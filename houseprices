#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sat Apr  1 14:11:49 2017

@author: NNK
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
import matplotlib.pyplot as plt



#%%

htrain = pd.read_csv('train.csv')
htest = pd.read_csv('test.csv')

htrain = htrain.drop('Id', axis=1)

###
##   Note: change "YearBuilt", "YearSold", "YearRM"
#       to YearsSince vars..
##
###


#%%
# Convert dataframe to all numeric for training models
#
#-------------------------
# Fill NAs with 0 first step
htrain = htrain.fillna(value=0)

# Seperate numerical and non-numerical columns into dataframes
numht = htrain.select_dtypes(include = ['float64','int64'])
nonht = htrain.select_dtypes(exclude = ['float64','int64'])

#Create empty df and pass all columns from non-numeric df 
# converted to categorical
non2 = pd.DataFrame()
for column in nonht:
    non2[column] = pd.Categorical(nonht[column])

#Create another empty df and pass all columns from categorical df
# converted to codes    
nonC = pd.DataFrame()
for column in non2:
    nonC[column] = non2[column].cat.codes
    
#Combine the native numerical and newly converted dataframes
trNum = pd.concat([numht,nonC], axis=1)

#%%
#Set up training models

train, test = train_test_split(trNum, test_size = .3)

# Train outcome and predictors 
y = train.SalePrice
X = train.drop('SalePrice', axis=1)

# Test outcome and predictors
yt = test.SalePrice
Xt = test.drop('SalePrice', axis=1)

#%%
#Set model parameters
gbfit = GradientBoostingRegressor(n_estimators=1500, max_depth=2, loss='ls')

#Fit model
gbfit.fit(X=X, y=y)

accuracy = gbfit.score(Xt, yt)
predict = gbfit.predict(Xt)



plt.scatter(predict, yt)

#%%
# Model feature importances ranking
importances = gbfit.feature_importances_
indices = np.argsort(importances)[::-1]

print('Feature Importances')

for f in range(X.shape[1]):
    print("feature %s (%f)" % (list(X)[f], importances[indices[f]]))

#plot
feat_imp = pd.DataFrame({'Feature':list(X),
                         'Gini Importance':importances[indices]})
